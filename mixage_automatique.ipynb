{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import soundfile as sf\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "# List of the music files used for the mixing\n",
    "musicFiles = [\"musics/G-Sus - Eruption (Extended Mix).wav\",\n",
    "              \"musics/Ragunde & TBR - Illusion.wav\",\n",
    "              \"musics/Olly James x KEVU & Luca Testa - Not Around (Extended Mix).wav\",\n",
    "              \"musics/Abduction (Extended Mix).wav\",\n",
    "              \"musics/Ragunde & Nic Johnston - Force40 (Extended Mix).wav\"]\n",
    "\n",
    "# List of the parts to extract from each music\n",
    "toExtract = [[\"Intro\"],\n",
    "             [\"Pré-drop\"],\n",
    "             [\"Drop\"],\n",
    "             [\"Couplet\",\"Pré-drop\"],\n",
    "             [\"Drop\",\"Outro\"]]\n",
    "\n",
    "# Load the music files & save the data\n",
    "datas,samplerates = [],[]\n",
    "for musicFile in musicFiles:\n",
    "    y,sr = librosa.load(musicFile)\n",
    "    datas.append(y)\n",
    "    samplerates.append(sr)\n",
    "\n",
    "# Create all melspectrograms\n",
    "melspectrograms = []\n",
    "for data,samplerate in zip(datas,samplerates):\n",
    "    melspectrogram = librosa.feature.melspectrogram(y=data, sr=samplerate, power=1.0)\n",
    "    melspectrograms.append(melspectrogram)\n",
    "\n",
    "# Store the BPM, beats frames and beats timings of every music\n",
    "bpms,beatsFrames,beatsTimings = [],[],[]\n",
    "for data,samplerate in zip(datas,samplerates):\n",
    "    tempo,beats = librosa.beat.beat_track(y=data, sr=samplerate)\n",
    "    beatsTimings.append(librosa.frames_to_time(beats, sr=samplerate))\n",
    "    bpms.append(tempo)\n",
    "    beatsFrames.append(beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used all over the code\n",
    "\n",
    "# Permet de faire la moyenne sur l'ensemble des données situées entre deux intervalles donnés\n",
    "def beatIntervals(S,tab):\n",
    "    # Initialisation à vide\n",
    "    ret = []\n",
    "\n",
    "    # Itération sur les indices des beats\n",
    "    for i in range(len(tab)-1):\n",
    "\n",
    "        # Indices de début et de fin\n",
    "        firstIndex = tab[i]\n",
    "        lastIndex = tab[i+1]\n",
    "\n",
    "        # Extraction des valeurs\n",
    "        indices = np.array(range(firstIndex,lastIndex))\n",
    "        test = S[:,indices]\n",
    "\n",
    "        # Calcul de la moyenne\n",
    "        ret.append(np.mean(test,axis=1))\n",
    "    \n",
    "    # Conversion en NumPy-array et transposition\n",
    "    ret = np.array(ret)\n",
    "    ret = np.swapaxes(ret,1,0)    \n",
    "    return ret\n",
    "\n",
    "# Permet de calculer la matrice des distances entre les intervalles\n",
    "def distanceMatrix(intervals):\n",
    "    # Initialisation de la matrice carrée à 0\n",
    "    mat = np.zeros((intervals.shape[1],intervals.shape[1]))\n",
    "    for i in range(intervals.shape[1]):\n",
    "        for j in range(i+1,intervals.shape[1]):\n",
    "\n",
    "            # Calcul de la distance entre les intervalles i et j et remplissage de la matrice\n",
    "            mat[i][j] = mat[j][i] = (sp.spatial.distance.euclidean(intervals[:,i],intervals[:,j]))\n",
    "    return mat\n",
    "\n",
    "# Permet de construire la matrice de connectivité pour les beats\n",
    "def buildBeatsConnectivityMatrix(matrix):\n",
    "    ret = np.zeros((matrix.shape[1],matrix.shape[1]))\n",
    "    for i in range(matrix.shape[1]):\n",
    "        if i-1 >= 0:\n",
    "            ret[i][i-1] = 1\n",
    "        if i+1 < matrix.shape[1]:\n",
    "            ret[i][i+1] = 1\n",
    "    return ret\n",
    "\n",
    "# Permet de générer les scores de Silhouette Coefficient, Calinsky-Harabasz Index et Davies-Bouldin Index\n",
    "def generateAllScores(matrix,range):\n",
    "    silhouette_scores = np.empty((0))\n",
    "    calinsky_harabasz_scores = np.empty((0))\n",
    "    davies_bouldin_scores = np.empty((0))\n",
    "\n",
    "    for i in range:\n",
    "        clustering = AgglomerativeClustering(n_clusters=i,connectivity=buildBeatsConnectivityMatrix(matrix),metric='euclidean',linkage='ward',compute_full_tree=True)\n",
    "        model = clustering.fit_predict(matrix)\n",
    "        labels = clustering.labels_\n",
    "\n",
    "        silhouette_score = metrics.silhouette_score(matrix, labels, metric='euclidean')\n",
    "        calinski_harabasz_score = metrics.calinski_harabasz_score(matrix, labels)\n",
    "        davies_bouldin_score = metrics.davies_bouldin_score(matrix, labels)\n",
    "\n",
    "        silhouette_scores = np.append(silhouette_scores,silhouette_score)\n",
    "        calinsky_harabasz_scores = np.append(calinsky_harabasz_scores,calinski_harabasz_score)\n",
    "        davies_bouldin_scores = np.append(davies_bouldin_scores,davies_bouldin_score)\n",
    "\n",
    "    return silhouette_scores,calinsky_harabasz_scores,davies_bouldin_scores\n",
    "\n",
    "# Permet d'utiliser les scores générés précédemment pour établir un classement et choisir le meilleur nombre de clusters\n",
    "def rankingBestNumberClusters(x,silhouette_scores,calinsky_harabasz_scores,davies_bouldin_scores):\n",
    "    sil_Ranks = np.zeros(x.shape[0])\n",
    "    cal_ha_Ranks = np.zeros(x.shape[0])\n",
    "    dav_bou_Ranks = np.zeros(x.shape[0])\n",
    "\n",
    "    alt_sil = np.sort(silhouette_scores)[::-1]\n",
    "    alt_cal = np.sort(calinsky_harabasz_scores)[::-1]\n",
    "    alt_dav = np.sort(davies_bouldin_scores)\n",
    "\n",
    "    while alt_sil.shape[0] != 0:\n",
    "        silMax = np.max(alt_sil)\n",
    "        indice = np.where(silhouette_scores == silMax)[0][0]\n",
    "        sil_Ranks[indice] = math.floor(x.shape[0] - alt_sil.shape[0] + 1)\n",
    "        alt_sil = np.delete(alt_sil,0)\n",
    "\n",
    "    while alt_cal.shape[0] != 0:\n",
    "        calMax = np.max(alt_cal)\n",
    "        indice = np.where(calinsky_harabasz_scores == calMax)[0][0]\n",
    "        cal_ha_Ranks[indice] = math.floor(x.shape[0] - alt_cal.shape[0] + 1)\n",
    "        alt_cal = np.delete(alt_cal,0)\n",
    "\n",
    "    while alt_dav.shape[0] != 0:\n",
    "        davMin = np.min(alt_dav)\n",
    "        indice = np.where(davies_bouldin_scores == davMin)[0][0]\n",
    "        dav_bou_Ranks[indice] = math.floor(x.shape[0] - alt_dav.shape[0] + 1)\n",
    "        alt_dav = np.delete(alt_dav,0)\n",
    "\n",
    "    total = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        total[i] = sil_Ranks[i] + cal_ha_Ranks[i] + dav_bou_Ranks[i]\n",
    "\n",
    "    total_Ranks = np.zeros(x.shape[0])\n",
    "    copy = total.copy()\n",
    "\n",
    "    while copy.shape[0] != 0:\n",
    "        totalMin = np.min(copy)\n",
    "        indice = np.where(total == totalMin)[0]\n",
    "        for elt in indice:\n",
    "            total_Ranks[elt] = math.floor(x.shape[0] - copy.shape[0] + 1)\n",
    "        for elt in indice:\n",
    "            copy = copy[copy != totalMin]\n",
    "\n",
    "    final = np.empty((0))\n",
    "\n",
    "    for rank in range(1,x.shape[0]+1):\n",
    "        for k in range(x.shape[0]-1,-1,-1):\n",
    "            if total_Ranks[k] == rank:\n",
    "                final = np.append(final,x[k])\n",
    "\n",
    "    return final[0]\n",
    "\n",
    "# Permet de déterminer les clusters à partir de la matrice de distances et du nombre de clusters idéal\n",
    "def determineClusters(matrix,idealClusterNb):\n",
    "    clustering = AgglomerativeClustering(n_clusters=int(idealClusterNb),connectivity=buildBeatsConnectivityMatrix(matrix),metric='euclidean',linkage='ward',compute_full_tree=True)\n",
    "    model = clustering.fit_predict(matrix)\n",
    "\n",
    "    labels = clustering.labels_\n",
    "\n",
    "    # Minimum size of clusters\n",
    "    min_cluster_size = 16\n",
    "\n",
    "    # Calculate the size of each cluster\n",
    "    cluster_sizes = np.bincount(model)\n",
    "\n",
    "    # Order all the clusters by their minimal index\n",
    "    clusters = np.argsort([np.min(np.where(model == i)[0]) for i in range(clustering.n_clusters_)])\n",
    "\n",
    "    # Merge the two first clusters while they are smaller than the minimum size\n",
    "    while cluster_sizes[clusters[0]] < min_cluster_size:\n",
    "        model[model == clusters[0]] = clusters[1]\n",
    "        cluster_sizes[clusters[1]] += cluster_sizes[clusters[0]]\n",
    "        cluster_sizes[clusters[0]] = 0\n",
    "        clusters = np.delete(clusters,0)\n",
    "\n",
    "    # Find the clusters that are smaller than the minimum size\n",
    "    small_clusters = np.where(cluster_sizes < min_cluster_size)[0]\n",
    "\n",
    "    # Erase the labels of the small clusters which don't contain any beat\n",
    "    for small_cluster in small_clusters:\n",
    "        if cluster_sizes[small_cluster] == 0:\n",
    "            small_clusters = np.delete(small_clusters,np.where(small_clusters == small_cluster))\n",
    "\n",
    "    # Get the minimum index of each small cluster\n",
    "    min_indices = [np.min(np.where(labels == i)[0]) for i in small_clusters]\n",
    "\n",
    "    # Sort the small clusters in ascending order of their minimum index\n",
    "    small_clusters = small_clusters[np.argsort(min_indices)]\n",
    "\n",
    "    # For each small cluster\n",
    "    for small_cluster in small_clusters:\n",
    "        # Find the indices of the small cluster\n",
    "        indices_small_cluster = np.where(model == small_cluster)[0]\n",
    "\n",
    "        # Find the nearest larger cluster in terms of index proximity\n",
    "        min_distance = np.inf\n",
    "        nearest_larger_cluster = None\n",
    "        for larger_cluster in np.where(cluster_sizes >= min_cluster_size)[0]:\n",
    "            # Find the indices of the larger cluster\n",
    "            indices_larger_cluster = np.where(model == larger_cluster)[0]\n",
    "\n",
    "            if indices_larger_cluster[-1] < indices_small_cluster[0]:\n",
    "                # Calculate the minimum absolute difference between the indices\n",
    "                distance = np.min(np.abs(indices_small_cluster[:, None] - indices_larger_cluster))\n",
    "\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    nearest_larger_cluster = larger_cluster\n",
    "        # Merge the small cluster into the nearest larger cluster\n",
    "        model[model == small_cluster] = nearest_larger_cluster\n",
    "\n",
    "    cluster_sizes = np.bincount(model)\n",
    "\n",
    "    clusters = []\n",
    "\n",
    "    for i in range(clustering.n_clusters_+1):\n",
    "        clusters.append(np.where(model == i))\n",
    "\n",
    "    clusters = [x for x in clusters if len(x[0]) > 0]\n",
    "\n",
    "    clusters.sort(reverse=False,key=lambda x : x[0][0])\n",
    "\n",
    "    limits = np.zeros(len(clusters)*2)\n",
    "\n",
    "    for i in range(len(clusters)):\n",
    "        limits[2*i] = math.floor(clusters[i][0][0])\n",
    "        limits[2*i+1] = math.floor(clusters[i][0][len(clusters[i][0])-1])\n",
    "\n",
    "    limits = limits.reshape(-1,2)\n",
    "    limits = np.int_(limits)\n",
    "\n",
    "    return limits\n",
    "\n",
    "# Permet de générer toutes les sous-parties d'une musique en fonction des clusters déterminés précédemment\n",
    "def generatePartsWithClusteringBeats(tab,beatsTimings,nb):\n",
    "    array = []\n",
    "\n",
    "    donnees,samplerate = sf.read(musicFiles[nb])\n",
    "    print(\"Durée de la musique :\",donnees.shape[0]//(60*samplerate),\"minutes\",(donnees.shape[0]%(samplerate*60))//(samplerate),\"secondes\")\n",
    "\n",
    "    for i in range(len(tab)):\n",
    "        beginBeat = tab[i][0]\n",
    "        endBeat = tab[i][1]\n",
    "\n",
    "        beginTime = beatsTimings[beginBeat]\n",
    "        endTime = beatsTimings[endBeat]\n",
    "\n",
    "        if i == 0:\n",
    "            beginData = 0\n",
    "        else:\n",
    "            beginData = math.floor(beginTime*samplerate)+1\n",
    "\n",
    "        if i == len(tab)-1:\n",
    "            endData = len(donnees)-1\n",
    "        else:\n",
    "            endTime = beatsTimings[endBeat+1]\n",
    "            endData = math.floor(endTime*samplerate)\n",
    "\n",
    "        print(beginData,endData)\n",
    "\n",
    "        data = donnees[beginData:endData]\n",
    "        array.append(data)\n",
    "        filename = \"clusters/song\"+str(nb+1)\n",
    "        if not os.path.exists(filename):\n",
    "            os.makedirs(filename)\n",
    "        filename = filename+\"/part\"+str(i+1)+\".wav\"\n",
    "        sf.write(filename,data,samplerate,'PCM_16')\n",
    "\n",
    "    return array\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durée de la musique : 3 minutes 57 secondes\n",
      "0 704400\n",
      "704401 1315178\n",
      "1315179 2433079\n",
      "2433080 4544052\n",
      "4544053 5158173\n",
      "5158174 6289449\n",
      "6289450 7052921\n",
      "7052922 7687105\n",
      "7687106 8384818\n",
      "8384819 9082531\n",
      "9082532 9780244\n",
      "9780245 10392137\n",
      "10392138 11407499\n",
      "Durée de la musique : 3 minutes 42 secondes\n",
      "0 774617\n",
      "774618 1477903\n",
      "1477904 2192335\n",
      "2192336 2901194\n",
      "2901195 3520888\n",
      "3520889 4253152\n",
      "4253153 4850555\n",
      "4850556 5581705\n",
      "5581706 6269387\n",
      "6269388 7664814\n",
      "7664815 8379245\n",
      "8379246 9103708\n",
      "9103709 9791390\n",
      "9791391 10659631\n",
      "Durée de la musique : 3 minutes 2 secondes\n",
      "0 620808\n",
      "620809 1159140\n",
      "1159141 2464287\n",
      "2464288 3079523\n",
      "3079524 3616740\n",
      "3616741 4461574\n",
      "4461575 5017739\n",
      "5017740 6305053\n",
      "6305054 6919174\n",
      "6919175 7533296\n",
      "7533297 8071627\n",
      "8071628 8749836\n",
      "Durée de la musique : 3 minutes 50 secondes\n",
      "0 669849\n",
      "669850 1253877\n",
      "1253878 2005089\n",
      "2005090 2672709\n",
      "2672710 3665780\n",
      "3665781 6011924\n",
      "6011925 7473110\n",
      "7473111 8015899\n",
      "8015900 9268662\n",
      "9268663 11085216\n",
      "Durée de la musique : 3 minutes 39 secondes\n",
      "0 663161\n",
      "663162 1241617\n",
      "1241618 2799769\n",
      "2799770 4109374\n",
      "4109375 4941949\n",
      "4941950 7572305\n",
      "7572306 8244384\n",
      "8244385 8891942\n",
      "8891943 9549531\n",
      "9549532 10521983\n"
     ]
    }
   ],
   "source": [
    "# Création des intervalles pour chaque musique\n",
    "intervals = []\n",
    "for melspectrogram,beatsFrame in zip(melspectrograms,beatsFrames):\n",
    "    intervals.append(beatIntervals(melspectrogram,beatsFrame))\n",
    "\n",
    "# Création des matrices de distances pour chaque musique\n",
    "distanceMatrixes = []\n",
    "for interval in intervals:\n",
    "    distanceMatrixes.append(distanceMatrix(interval))\n",
    "\n",
    "# Génération des scores pour chaque musique\n",
    "scores = []\n",
    "for distanceMatrix in distanceMatrixes:\n",
    "    scores.append(generateAllScores(distanceMatrix,np.arange(12,26)))\n",
    "\n",
    "# Établissement des nombres de clusters idéaux pour chaque musique\n",
    "idealClusterNbs = []\n",
    "for score in scores:\n",
    "    idealClusterNbs.append(rankingBestNumberClusters(np.arange(12,26),score[0],score[1],score[2]))\n",
    "\n",
    "# Création des clusters pour chaque musique\n",
    "clusters = []\n",
    "clusteredMusics = []\n",
    "\n",
    "for distanceMatrix,idealClusterNb in zip(distanceMatrixes,idealClusterNbs):\n",
    "    clusters.append(determineClusters(distanceMatrix,idealClusterNb))\n",
    "\n",
    "if not os.path.exists(\"clusters\"):\n",
    "    os.makedirs(\"clusters\")\n",
    "\n",
    "for nb in range(len(musicFiles)):\n",
    "    clusteredMusic = generatePartsWithClusteringBeats(clusters[nb],beatsTimings[nb],nb)\n",
    "    clusteredMusics.append(clusteredMusic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permet de déterminer un étiquettage pour chaque sous-partie de musique\n",
    "def determineTags(tab,spec,beat):\n",
    "    arr = []\n",
    "    \n",
    "    for i in range(len(tab)):\n",
    "        beginBeat = tab[i][0]\n",
    "        endBeat = tab[i][1]\n",
    "\n",
    "        beginPart = beat[beginBeat]\n",
    "        endPart = beat[endBeat+1]\n",
    "\n",
    "        if i == 0:\n",
    "            beginPart = 0\n",
    "\n",
    "        if i == len(tab)-1:\n",
    "            endPart = spec.shape[1]-1\n",
    "\n",
    "        part = spec[:,beginPart:endPart]\n",
    "\n",
    "        arr.append(np.median(part,axis=1))\n",
    "\n",
    "    arr = np.array(arr)\n",
    "\n",
    "    arr2 = []\n",
    "\n",
    "    for elt in range(arr.shape[0]):\n",
    "        arr2.append(np.sum(arr[elt]))\n",
    "\n",
    "    arr2 = np.array(arr2)\n",
    "\n",
    "    tags = []\n",
    "    for i in range(len(tab)):\n",
    "        tags.append(\"\")\n",
    "\n",
    "    indMax = np.argmax(arr2)\n",
    "    tags[indMax] = \"Drop\"\n",
    "\n",
    "    tags[0] = \"Intro\"\n",
    "    tags[len(tab)-1] = \"Outro\"\n",
    "\n",
    "    for i in range(len(tab)):\n",
    "        if arr2[i] > 0.9*arr2[indMax] and i>1:\n",
    "            tags[i] = \"Drop\"\n",
    "        elif tags[i-1] == \"Intro\" and tags[i] == \"\" and not i>1:\n",
    "            tags[i] = \"Intro\"\n",
    "\n",
    "    for i in range(len(tab)-1):\n",
    "        if tags[i-1] == \"Drop\" and tags[i+1] == 'Outro':\n",
    "            tags[i] = \"Outro\"\n",
    "\n",
    "    for i in range(len(tab)):\n",
    "        if tags[i] == \"\" and tags[i+1] == \"Drop\":\n",
    "            tags[i] = \"Pré-drop\"\n",
    "        elif tags[i] == \"\":\n",
    "            tags[i] = \"Couplet\"\n",
    "\n",
    "    for i in range(len(tab)):\n",
    "        if tags[i-2] == \"Drop\" and tags[i-1] == \"Couplet\" and tags[i] == \"Couplet\" and 2/3*arr2[i-2] < arr2[i-1]:\n",
    "            tags[i-1] = \"Drop\"\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intro', 'Intro', 'Couplet', 'Pré-drop', 'Drop', 'Couplet', 'Couplet', 'Couplet', 'Pré-drop', 'Drop', 'Drop', 'Outro', 'Outro']\n",
      "['Intro', 'Intro', 'Couplet', 'Pré-drop', 'Drop', 'Couplet', 'Couplet', 'Couplet', 'Couplet', 'Pré-drop', 'Drop', 'Drop', 'Outro', 'Outro']\n",
      "['Intro', 'Intro', 'Couplet', 'Pré-drop', 'Drop', 'Couplet', 'Couplet', 'Pré-drop', 'Drop', 'Drop', 'Outro', 'Outro']\n",
      "['Intro', 'Intro', 'Pré-drop', 'Drop', 'Drop', 'Couplet', 'Couplet', 'Pré-drop', 'Drop', 'Outro']\n",
      "['Intro', 'Intro', 'Pré-drop', 'Drop', 'Couplet', 'Pré-drop', 'Drop', 'Drop', 'Outro', 'Outro']\n"
     ]
    }
   ],
   "source": [
    "# Détermination des étiquettes pour chaque sous-partie de musique\n",
    "musicTags = []\n",
    "\n",
    "for nb in range(len(musicFiles)):\n",
    "    S = melspectrograms[nb]\n",
    "    limits = clusters[nb]\n",
    "    beats = beatsFrames[nb]\n",
    "\n",
    "    musicTags.append(determineTags(limits,S,beats))\n",
    "\n",
    "for elt in musicTags:\n",
    "    print(elt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixage terminé !\n"
     ]
    }
   ],
   "source": [
    "# Permet de déterminer la plus longue chaîne de nombres consécutifs dans une liste\n",
    "def longestChain(tab):\n",
    "    # Sort each subarray\n",
    "    for sub in tab:\n",
    "        sub.sort()\n",
    "\n",
    "    # Create a dictionary to store the longest chain ending at each number\n",
    "    dp = {}\n",
    "\n",
    "    for i, sub in enumerate(tab):\n",
    "        for num in sub:\n",
    "            # If it's in the first subarray, set the longest chain ending at this number to [num]\n",
    "            # If it's not in the first subarray, set the longest chain ending at this number to the longest chain of the previous number plus [num], if the previous number exists in the dictionary and the new chain is longer\n",
    "            if num - 1 in dp and (num not in dp or len(dp[num - 1]) + 1 > len(dp.get(num, []))):\n",
    "                dp[num] = dp[num - 1] + [num]\n",
    "            elif num not in dp:\n",
    "                dp[num] = [num]\n",
    "\n",
    "    # Find the longest chain\n",
    "    longest_chain = max(dp.values(), key=len)\n",
    "\n",
    "    # If the longest chain is of size 1, return the maximum number from the original list enclosed in an array\n",
    "    if len(longest_chain) == 1:\n",
    "        return [max(sum(tab, []))]  # sum(tab, []) flattens the list\n",
    "\n",
    "    # Return the longest chain\n",
    "    return longest_chain\n",
    "\n",
    "# Permet de générer le mixage final\n",
    "chosenParts = []\n",
    "\n",
    "for i in range(len(toExtract)):\n",
    "    elements = toExtract[i]\n",
    "\n",
    "    tags = musicTags[i]\n",
    "\n",
    "    indices = []\n",
    "    for elt in elements:\n",
    "        sub = []\n",
    "        for j in range(len(tags)):\n",
    "            if tags[j] == elt:\n",
    "                sub.append(j+1)\n",
    "        indices.append(sub)\n",
    "\n",
    "    chosenParts.append(longestChain(indices))\n",
    "\n",
    "musicParts = []\n",
    "for i in range(len(musicFiles)):\n",
    "    \n",
    "    test = []\n",
    "    chosen = chosenParts[i]\n",
    "    for elt in chosen:\n",
    "        filename = \"clusters/song\"+str(i+1)+\"/part\"+str(elt)+\".wav\"\n",
    "        data,samplerate = sf.read(filename)\n",
    "        musicParts.append(data)\n",
    "\n",
    "sf.write(\"result/final_mix.wav\",np.concatenate(musicParts),samplerate,'PCM_16')\n",
    "\n",
    "if os.path.exists(\"clusters\"):\n",
    "    shutil.rmtree(\"clusters\")\n",
    "\n",
    "print(\"Mixage terminé !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
